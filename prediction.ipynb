{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (1.57.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from openai) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mukar\\anaconda3\\envs\\taskvenv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x={\n",
    "  \"id\": \"\",\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"finish_reason\": \"stop\",\n",
    "      \"index\": 0,\n",
    "      \"logprobs\": None,\n",
    "      \"message\": {\n",
    "        \"content\": \"Why did Mukarram bring a pillow to his meeting? \\n\\nBecause he heard it was time to \\\"rest\\\" his case!\",\n",
    "        \"refusal\": None,\n",
    "        \"role\": \"assistant\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"created\": 1733575269,\n",
    "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"system_fingerprint\": \"fp_bba3c8e70b\",\n",
    "  \"usage\": {\n",
    "    \"completion_tokens\": 26,\n",
    "    \"prompt_tokens\": 31,\n",
    "    \"total_tokens\": 57,\n",
    "    \"completion_tokens_details\": {\n",
    "      \"accepted_prediction_tokens\": 0,\n",
    "      \"audio_tokens\": 0,\n",
    "      \"reasoning_tokens\": 0,\n",
    "      \"rejected_prediction_tokens\": 0\n",
    "    },\n",
    "    \"prompt_tokens_details\": {\n",
    "      \"audio_tokens\": 0,\n",
    "      \"cached_tokens\":0\n",
    "}\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did Mukarram bring a pillow to his meeting? \\n\\nBecause he heard it was time to \"rest\" his case!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client= OpenAI(api_key=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of course! I'm here to help. Please let me know the specific tasks or questions you have regarding machine learning, and I'll do my best to assist you. Whether it's about algorithms, model evaluation, data preprocessing, or anything else, feel free to elaborate!\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "cliopenai.api_key =\n",
    "\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"As a Machine Learning Expert, assist me in my tasks.\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(input_text):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"As a Machine Learning Expert, assist me in my tasks.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": input_text\n",
    "        }\n",
    "    ]\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    reply = completion.choices[0].message[\"content\"]\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(file_path):\n",
    "    with open(file_path,'r') as file:\n",
    "        return yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config=load_config('config.yaml')\n",
    "tools=config['openai_tool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtools\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtool1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tools' is not defined"
     ]
    }
   ],
   "source": [
    "tools['tool1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinydb import TinyDB,Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_db=TinyDB(\"users.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_db.default_table_name = \"students\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Bobby','Sunny','Shaggy']\n",
    "age  = [18,19,20]\n",
    "user_id = [1,2,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Bobby', 18, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name[0],age[0],user_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in range(len(name)):\n",
    "    users_db.insert({'name': name[user], 'age': age[user],'user_id': user_id[user]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('users.json') as file:\n",
    "    users=json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'students': {'1': {'name': 'Bobby', 'age': 18, 'user_id': 1},\n",
       "  '2': {'name': 'Sunny', 'age': 19, 'user_id': 2},\n",
       "  '3': {'name': 'Shaggy', 'age': 20, 'user_id': 9}}}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': {'name': 'Bobby', 'age': 18, 'user_id': 1},\n",
       " '2': {'name': 'Sunny', 'age': 19, 'user_id': 2},\n",
       " '3': {'name': 'Shaggy', 'age': 20, 'user_id': 9}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['students']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "User = Query()\n",
    "if users_db.search(User.user_id == 1):\n",
    "    print(\"there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_user(u_id):\n",
    "    for user in users['students']:\n",
    "        print(user)\n",
    "        if any(users['students'][user]['user_id'] == u_id):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "##[student['user_id'] for student in users['students'].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcheck_user\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[24], line 4\u001b[0m, in \u001b[0;36mcheck_user\u001b[1;34m(u_id)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user \u001b[38;5;129;01min\u001b[39;00m users[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudents\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(user)\n\u001b[1;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43musers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstudents\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43muser\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mu_id\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    }
   ],
   "source": [
    "check_user(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_userid(u_id):\n",
    "    if any(student['user_id'] == u_id for student in users['students'].values()):\n",
    "        print('there')\n",
    "    else:\n",
    "        print('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n"
     ]
    }
   ],
   "source": [
    "check_userid(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 9]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[student['user_id'] for student in users['students'].values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "list2=list(map(lambda student: student['user_id'], users['students'].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 9]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(student['user_id'] == 5 for student in users['students'].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('users.json') as file:\n",
    "    users=json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtinydb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Query,TinyDB\n\u001b[0;32m      2\u001b[0m User \u001b[38;5;241m=\u001b[39m Query()\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43musers\u001b[49m\u001b[38;5;241m.\u001b[39msearch(User\u001b[38;5;241m.\u001b[39muser_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll good\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'users' is not defined"
     ]
    }
   ],
   "source": [
    "from tinydb import Query,TinyDB\n",
    "User = Query()\n",
    "if users.search(User.user_id == 1):\n",
    "    print(\"All good\")\n",
    "else:\n",
    "    print(\"No Good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_user_db\n",
    "users_db=get_user_db()\n",
    "User = Query()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_db.search(User.name==\"Sunn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "def load_config(file_path):\n",
    "    with open(file_path,'r') as file:\n",
    "        return yaml.safe_load(file)\n",
    "    \n",
    "config=load_config('config.yaml')\n",
    "tools=config['openai_tool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_params_and_roles(input_text:str):\n",
    "        for t in tools['messages']:\n",
    "            if '{input_text}' in t['content']:\n",
    "                t['content'] = t['content'].replace(\"{input_text}\", input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'role': 'system',\n",
       "   'content': 'SafeeBhai: As a Machine Learning Expert.'},\n",
       "  {'role': 'user', 'content': '{input_text}'}],\n",
       " 'model': 'gpt-4o-mini',\n",
       " 'temperature': 0.6,\n",
       " 'max_tokens': 40}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools['tool1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'openai_tool': {'tool1': {'messages': [{'role': 'system', 'content': 'SafeeBhai: As a Machine Learning Expert.'}, {'role': 'user', 'content': '{input_text}'}], 'model': 'gpt-4o-mini', 'temperature': 0.6, 'max_tokens': 40}, 'tool2': {'messages': [{'role': 'system', 'content': 'As a Storyteller, make each and everything romantic.'}, {'role': 'user', 'content': '{input_text}'}], 'model': 'gpt-4o-mini', 'temperature': 1.0, 'max_tokens': 100}, 'tool3': {'messages': [{'role': 'system', 'content': 'As a Jokester, make fun of everything.'}, {'role': 'user', 'content': '{input_text}'}], 'model': 'gpt-4o-mini', 'temperature': 0.9, 'max_tokens': 120}}}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taskvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
